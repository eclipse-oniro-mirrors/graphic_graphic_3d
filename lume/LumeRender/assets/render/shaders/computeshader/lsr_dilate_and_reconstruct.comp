#version 460 core
#extension GL_ARB_separate_shader_objects : enable
#extension GL_ARB_shading_language_420pack : enable

// Lume Super Resolution

// 1. Dilate depth and motion vectors
// 2. Reconstruct previous frame depthmap based on dilated depth and motion vectors
// 3. Calculate input Lock luma texture

// includes
#include "render/shaders/common/render_color_conversion_common.h"
#include "render/shaders/common/render_post_process_structs_common.h"

#include "common/bloom_common.h"

// sets

layout(set = 0, binding = 0, r32ui)  uniform uimage2D previousDepthTex;
layout(set = 0, binding = 1, r16ui)   uniform writeonly uimage2D  dilatedDepthTex; 
layout(set = 0, binding = 2) uniform sampler uSampler;
layout(set = 0, binding = 3, rg16f)  uniform image2D   dilatedMotionTex;  
layout(set = 0, binding = 4, r16f)   uniform image2D   lockInputLumaTex;   

layout(set = 0, binding = 5) uniform texture2D depthTex;
layout(set = 0, binding = 6) uniform texture2D velocityTex;
layout(set = 0, binding = 7) uniform texture2D colorTex;

// #define INVERTED_DEPTH 1

layout(push_constant, std430) uniform uPostProcessPushConstant
{
    LocalPostProcessPushConstantStruct uPc;
};

layout(constant_id = 0) const uint CORE_POST_PROCESS_FLAGS = 0;

//---------------- Utility Functions ------------------//

ivec2 RenderSize() {
    return ivec2(uPc.viewportSizeInvSize.x, uPc.viewportSizeInvSize.y);
}

bool OnScreen(ivec2 pos, ivec2 size) {
    return (pos.x >= 0 && pos.y >= 0 && pos.x < size.x && pos.y < size.y);
}

float LoadDepth(ivec2 coord) {
    vec2 uv = (vec2(coord) + 0.5) * uPc.viewportSizeInvSize.zw;
    return texture(sampler2D(depthTex, uSampler), uv).r;
}

vec2 LoadVelocity(ivec2 coord) {
    vec2 uv = (vec2(coord) + 0.5) * uPc.viewportSizeInvSize.zw;
    return texture(sampler2D(velocityTex, uSampler), uv).rg;
}

vec3 LoadColor(ivec2 coord) {
    vec2 uv = (vec2(coord) + 0.5) * uPc.viewportSizeInvSize.zw;
    return texture(sampler2D(colorTex, uSampler), uv).rgb;
}

float Exposure() { return 0.7f; }

/*
Aces tonemapping.
https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/
*/
vec3 TonemapAces(vec3 x)
{
    const float a = 2.51f;
    const float b = 0.03f;
    const float c = 2.43f;
    const float d = 0.59f;
    const float e = 0.14f;
    return (x * (a * x + b)) / (x * (c * x + d) + e);
}

vec3 Tonemap(vec3 rgb)
{
    return rgb / (max(max(0.f, rgb.r), max(rgb.g, rgb.b)) + 1.f).xxx;
}

vec3 InverseTonemap(vec3 rgb)
{
    return rgb / max(1e-0001, 1.f - max(rgb.r, max(rgb.g, rgb.b))).xxx;
}

float perceivedLuma(float luma)
{
    float percievedLuminance = 0;
    if (luma <= 216.0 / 24389.0) {
        percievedLuminance = luma * (24389.0 / 27.0);
    }
    else {
        percievedLuminance = pow(luma, 1.0 / 3.0) * 116.0 - 16.0;
    }

    return percievedLuminance * 0.01;
}

float ComputeLockInputLuma(ivec2 coord) 
{
    vec3 color = max(vec3(0.0), LoadColor(coord));  
    color *= Exposure();
    color = TonemapAces(color);
    float luma = perceivedLuma(CalcLuma(color));
    return pow(luma, 1.0 / 6.0);
}

struct NearestDepthResult {
    float depth;
    ivec2 coord;
};

// Sample offsets for a 3Ã—3 dilation
const ivec2 DILATE_OFFSETS[9] = ivec2[](
    ivec2(0,0), ivec2(1,0), ivec2(-1,0), ivec2(0,1), ivec2(0,-1),
    ivec2(-1,1), ivec2(1,1), ivec2(-1,-1), ivec2(1,-1)
);

// Method based on FSR 2.3.2 implementation
NearestDepthResult FindNearestDepth(ivec2 center) {
    float bestDepth = LoadDepth(center);
    ivec2 bestCoord = center;

    for (int i = 0; i < 9; i++) {
        ivec2 sampleCoord = center + DILATE_OFFSETS[i];
        // bounds check
        if (sampleCoord.x < 0 || sampleCoord.y < 0 
         || sampleCoord.x >= int(uPc.viewportSizeInvSize.x)
         || sampleCoord.y >= int(uPc.viewportSizeInvSize.y)) 
        {
            continue;
        }
        float d = LoadDepth(sampleCoord);
        if (d < bestDepth) {
            bestDepth = d;
            bestCoord = sampleCoord;
        }
    }

    NearestDepthResult r;
    r.depth = bestDepth;
    r.coord = bestCoord;
    return r;
}

struct BilinearSamplingData {
    ivec2 basePos;
    ivec2 offsets[4];
    float weights[4];
};

// Compute bilinear weights and offsets around a given UV
BilinearSamplingData GetBilinearSamplingData(vec2 fUV, ivec2 iSize) {
    BilinearSamplingData d;

    // Convert UV to pixel space
    vec2 pixelPos = fUV * vec2(iSize);
    vec2 frac = fract(pixelPos);

    d.basePos = ivec2(floor(pixelPos));
    d.offsets[0] = ivec2(0, 0);
    d.offsets[1] = ivec2(1, 0);
    d.offsets[2] = ivec2(0, 1);
    d.offsets[3] = ivec2(1, 1);

    float w00 = (1.0 - frac.x) * (1.0 - frac.y);
    float w10 = frac.x * (1.0 - frac.y);
    float w01 = (1.0 - frac.x) * frac.y;
    float w11 = frac.x * frac.y;

    d.weights[0] = w00;
    d.weights[1] = w10;
    d.weights[2] = w01;
    d.weights[3] = w11;

    return d;
}

void StoreReconstructedDepth(ivec2 pos, float depth) {
    uint uDepth = floatBitsToUint(depth);
    imageAtomicMin(previousDepthTex, pos, uDepth);
}

void SetReconstructedDepth(ivec2 pos, uint uValue) {
    imageStore(previousDepthTex, pos, uvec4(uValue, 0, 0, 0));
}

uint EncodeDepthToR16UI(float depth) {
    float clampedDepth = clamp(depth, 0.0, 1.0);
    return uint(round(clampedDepth * 65535.0));
}

const float weightThreshold = 0.000001;

// Function based on ARM asr implementation (FSR 2.3.2)
void ReconstructPrevDepth(ivec2 pos, float depth, vec2  motionVector, ivec2 size) 
{
    float motionLength = length(motionVector);

    if (motionLength <= 0.001) {
        motionVector = vec2(0.0);
    }
    // Current UV
    vec2 uv = (vec2(pos) + 0.5) / vec2(size);
    // Reprojected UV
    vec2 reprojectedUv = clamp(uv - motionVector, vec2(0.0), vec2(1.0 - 1.0 / vec2(size)));

    BilinearSamplingData bilinearInfo = GetBilinearSamplingData(reprojectedUv, size);

    for (int iSampleIndex = 0; iSampleIndex < 4; iSampleIndex++) {
        ivec2 offset = bilinearInfo.offsets[iSampleIndex];
        float weight = bilinearInfo.weights[iSampleIndex];

        if (weight > weightThreshold) {
            ivec2 storePos = bilinearInfo.basePos + offset;
            if (OnScreen(storePos, size)) {
                StoreReconstructedDepth(storePos, depth);
            }
        }
    }
}


#define cTgs 8

layout(local_size_x = cTgs, local_size_y = cTgs, local_size_z = 1) in;
void main()
{
    const ivec2 gid = ivec2(gl_GlobalInvocationID.xy);
    const ivec2 size = RenderSize();

    if (gid.x >= int(uPc.viewportSizeInvSize.x)
     || gid.y >= int(uPc.viewportSizeInvSize.y)) {
        return;
    }
    if (!OnScreen(gid, size)) {
        return;
    }
    NearestDepthResult nearest = FindNearestDepth(gid);
    float dilatedDepth = nearest.depth;
    ivec2 bestDepthCoord = nearest.coord;

    vec2 dilatedMotion = LoadVelocity(bestDepthCoord);
    vec2 motionVectorUV = dilatedMotion / vec2(size);
    if (motionVectorUV.x < 0.001 && motionVectorUV.y < 0.001){
        motionVectorUV = vec2(0);
    }

    uint encodedDepth = EncodeDepthToR16UI(dilatedDepth);
    imageStore(dilatedDepthTex,  gid, uvec4(encodedDepth, 0, 0, 0));
    imageStore(dilatedMotionTex, gid, vec4(motionVectorUV.x, motionVectorUV.y, 0, 0));

    ReconstructPrevDepth(gid, dilatedDepth, motionVectorUV, size);
    vec3 color = vec3(0.0);
        float lockLuma = ComputeLockInputLuma(gid);
    imageStore(lockInputLumaTex, gid, vec4(lockLuma, 0, 0, 0));
}
